//! Comprehensive Integration Performance Benchmarks
//! 
//! This benchmark suite validates the performance requirements for the integrated
//! Monmouth SVM ExEx system, ensuring it meets SVM transaction processing speeds
//! and enterprise performance standards.

use criterion::{
    black_box, criterion_group, criterion_main, Criterion, BenchmarkId, 
    Throughput, BatchSize, measurement::WallTime, BenchmarkGroup,
};
use monmouth_svm_exex::*;
use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::runtime::Runtime;
use tokio::sync::{Mutex, RwLock};

/// Performance benchmark configuration
#[derive(Debug, Clone)]
pub struct BenchmarkConfig {
    /// Number of ExEx instances to simulate
    pub instance_count: usize,
    /// Number of iterations for throughput tests
    pub throughput_iterations: usize,
    /// Number of concurrent operations for stress tests
    pub stress_concurrency: usize,
    /// Enable stress testing
    pub enable_stress_tests: bool,
    /// Enable resource monitoring
    pub enable_resource_monitoring: bool,
}

impl Default for BenchmarkConfig {
    fn default() -> Self {
        Self {
            instance_count: 3,
            throughput_iterations: 1000,
            stress_concurrency: 100,
            enable_stress_tests: true,
            enable_resource_monitoring: true,
        }
    }
}

/// Benchmark context for managing test instances
pub struct BenchmarkContext {
    /// Test configuration
    config: BenchmarkConfig,
    /// Mock ExEx instances
    instances: Vec<Arc<MockBenchmarkInstance>>,
    /// Runtime for async operations
    runtime: Arc<Runtime>,
}

/// Mock ExEx instance optimized for benchmarking
pub struct MockBenchmarkInstance {
    /// Instance ID
    pub id: String,
    /// Role
    pub role: InstanceRole,
    /// Message bus (mock)
    pub message_bus: Arc<MockMessageBus>,
    /// AI engine (mock)
    pub ai_engine: Arc<MockAIEngine>,
    /// Optimization service (mock)
    pub optimization: Arc<MockOptimizationService>,
    /// Batch manager (mock)
    pub batch_manager: Arc<MockBatchManager>,
    /// Health checker (mock)
    pub health_checker: Arc<MockHealthChecker>,
    /// Performance metrics
    pub metrics: Arc<RwLock<BenchmarkMetrics>>,
}

/// Instance role for benchmarking
#[derive(Debug, Clone, Copy)]
pub enum InstanceRole {
    Coordinator,
    Analyzer,
    Optimizer,
    Monitor,
}

/// Benchmark-specific metrics
#[derive(Debug, Default, Clone)]
pub struct BenchmarkMetrics {
    /// Operations completed
    pub operations_completed: u64,
    /// Total latency (ms)
    pub total_latency_ms: f64,
    /// Success count
    pub success_count: u64,
    /// Error count
    pub error_count: u64,
    /// Memory usage (bytes)
    pub memory_usage_bytes: u64,
    /// CPU time (ms)
    pub cpu_time_ms: f64,
}

/// Mock message bus for benchmarking
pub struct MockMessageBus {
    /// Message count
    message_count: Arc<Mutex<u64>>,
    /// Latency simulation
    latency_simulation_ms: Arc<Mutex<f64>>,
}

/// Mock AI engine for benchmarking
pub struct MockAIEngine {
    /// Decision count
    decision_count: Arc<Mutex<u64>>,
    /// Processing time simulation
    processing_time_ms: Arc<Mutex<f64>>,
}

/// Mock optimization service for benchmarking
pub struct MockOptimizationService {
    /// Query count
    query_count: Arc<Mutex<u64>>,
    /// Cache hit simulation rate
    cache_hit_rate: Arc<Mutex<f64>>,
}

/// Mock batch manager for benchmarking
pub struct MockBatchManager {
    /// Batch count
    batch_count: Arc<Mutex<u64>>,
    /// Throughput simulation
    throughput_ops_per_sec: Arc<Mutex<f64>>,
}

/// Mock health checker for benchmarking
pub struct MockHealthChecker {
    /// Health check count
    check_count: Arc<Mutex<u64>>,
    /// Check latency simulation
    check_latency_ms: Arc<Mutex<f64>>,
}

impl BenchmarkContext {
    /// Create a new benchmark context
    pub fn new(config: BenchmarkConfig) -> Self {
        let runtime = Arc::new(
            tokio::runtime::Runtime::new()
                .expect("Failed to create tokio runtime")
        );

        let mut instances = Vec::new();
        for i in 0..config.instance_count {
            let role = match i {
                0 => InstanceRole::Coordinator,
                1 => InstanceRole::Analyzer,
                2 => InstanceRole::Optimizer,
                _ => InstanceRole::Monitor,
            };

            let instance = Arc::new(MockBenchmarkInstance::new(
                format!("bench-instance-{}", i),
                role,
            ));
            instances.push(instance);
        }

        Self {
            config,
            instances,
            runtime,
        }
    }

    /// Execute async operation in benchmark context
    pub fn execute_async<F, Fut, R>(&self, f: F) -> R
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = R>,
    {
        self.runtime.block_on(f())
    }
}

impl MockBenchmarkInstance {
    /// Create a new mock instance
    pub fn new(id: String, role: InstanceRole) -> Self {
        Self {
            id,
            role,
            message_bus: Arc::new(MockMessageBus::new()),
            ai_engine: Arc::new(MockAIEngine::new()),
            optimization: Arc::new(MockOptimizationService::new()),
            batch_manager: Arc::new(MockBatchManager::new()),
            health_checker: Arc::new(MockHealthChecker::new()),
            metrics: Arc::new(RwLock::new(BenchmarkMetrics::default())),
        }
    }

    /// Simulate cross-ExEx message sending
    pub async fn send_message_benchmark(&self) -> Duration {
        let start = Instant::now();
        
        // Simulate message processing
        self.message_bus.simulate_message_send().await;
        
        // Update metrics
        {
            let mut metrics = self.metrics.write().await;
            metrics.operations_completed += 1;
            metrics.success_count += 1;
        }
        
        start.elapsed()
    }

    /// Simulate AI decision making
    pub async fn ai_decision_benchmark(&self, transaction_data: &[u8]) -> Duration {
        let start = Instant::now();
        
        // Simulate AI processing
        self.ai_engine.simulate_decision(transaction_data.len()).await;
        
        // Update metrics
        {
            let mut metrics = self.metrics.write().await;
            metrics.operations_completed += 1;
            metrics.success_count += 1;
        }
        
        start.elapsed()
    }

    /// Simulate RAG query processing
    pub async fn rag_query_benchmark(&self, query: &str) -> Duration {
        let start = Instant::now();
        
        // Simulate RAG processing
        self.optimization.simulate_rag_query(query.len()).await;
        
        // Update metrics
        {
            let mut metrics = self.metrics.write().await;
            metrics.operations_completed += 1;
            metrics.success_count += 1;
        }
        
        start.elapsed()
    }

    /// Simulate memory operation
    pub async fn memory_operation_benchmark(&self, operation_size: usize) -> Duration {
        let start = Instant::now();
        
        // Simulate memory operation (simplified)
        let _data = vec![0u8; operation_size];
        tokio::task::yield_now().await;
        
        // Update metrics
        {
            let mut metrics = self.metrics.write().await;
            metrics.operations_completed += 1;
            metrics.success_count += 1;
            metrics.memory_usage_bytes += operation_size as u64;
        }
        
        start.elapsed()
    }

    /// Simulate batch processing
    pub async fn batch_processing_benchmark(&self, batch_size: usize) -> Duration {
        let start = Instant::now();
        
        // Simulate batch processing
        self.batch_manager.simulate_batch_processing(batch_size).await;
        
        // Update metrics
        {
            let mut metrics = self.metrics.write().await;
            metrics.operations_completed += batch_size as u64;
            metrics.success_count += batch_size as u64;
        }
        
        start.elapsed()
    }

    /// Simulate health check
    pub async fn health_check_benchmark(&self) -> Duration {
        let start = Instant::now();
        
        // Simulate health check
        self.health_checker.simulate_health_check().await;
        
        // Update metrics
        {
            let mut metrics = self.metrics.write().await;
            metrics.operations_completed += 1;
            metrics.success_count += 1;
        }
        
        start.elapsed()
    }

    /// Get current metrics
    pub async fn get_metrics(&self) -> BenchmarkMetrics {
        self.metrics.read().await.clone()
    }
}

// Mock implementations
impl MockMessageBus {
    fn new() -> Self {
        Self {
            message_count: Arc::new(Mutex::new(0)),
            latency_simulation_ms: Arc::new(Mutex::new(2.0)), // 2ms simulation
        }
    }

    async fn simulate_message_send(&self) {
        // Simulate network latency
        let latency = {
            let latency = self.latency_simulation_ms.lock().await;
            *latency
        };
        
        tokio::time::sleep(Duration::from_millis(latency as u64)).await;
        
        // Increment message count
        {
            let mut count = self.message_count.lock().await;
            *count += 1;
        }
    }
}

impl MockAIEngine {
    fn new() -> Self {
        Self {
            decision_count: Arc::new(Mutex::new(0)),
            processing_time_ms: Arc::new(Mutex::new(15.0)), // 15ms simulation
        }
    }

    async fn simulate_decision(&self, data_size: usize) {
        // Simulate AI processing time (scales with data size)
        let base_time = {
            let time = self.processing_time_ms.lock().await;
            *time
        };
        
        let scaled_time = base_time + (data_size as f64 * 0.001); // 1Î¼s per byte
        tokio::time::sleep(Duration::from_millis(scaled_time as u64)).await;
        
        // Increment decision count
        {
            let mut count = self.decision_count.lock().await;
            *count += 1;
        }
    }
}

impl MockOptimizationService {
    fn new() -> Self {
        Self {
            query_count: Arc::new(Mutex::new(0)),
            cache_hit_rate: Arc::new(Mutex::new(0.95)), // 95% hit rate
        }
    }

    async fn simulate_rag_query(&self, query_size: usize) {
        // Simulate cache lookup vs full query
        let hit_rate = {
            let rate = self.cache_hit_rate.lock().await;
            *rate
        };

        let is_cache_hit = rand::random::<f64>() < hit_rate;
        
        if is_cache_hit {
            // Cache hit - very fast
            tokio::time::sleep(Duration::from_millis(5)).await;
        } else {
            // Cache miss - slower processing
            let processing_time = 25.0 + (query_size as f64 * 0.01);
            tokio::time::sleep(Duration::from_millis(processing_time as u64)).await;
        }
        
        // Increment query count
        {
            let mut count = self.query_count.lock().await;
            *count += 1;
        }
    }
}

impl MockBatchManager {
    fn new() -> Self {
        Self {
            batch_count: Arc::new(Mutex::new(0)),
            throughput_ops_per_sec: Arc::new(Mutex::new(10000.0)), // 10K ops/sec
        }
    }

    async fn simulate_batch_processing(&self, batch_size: usize) {
        // Simulate batch processing time
        let throughput = {
            let tps = self.throughput_ops_per_sec.lock().await;
            *tps
        };

        let processing_time_ms = (batch_size as f64 / throughput) * 1000.0;
        tokio::time::sleep(Duration::from_millis(processing_time_ms as u64)).await;
        
        // Increment batch count
        {
            let mut count = self.batch_count.lock().await;
            *count += 1;
        }
    }
}

impl MockHealthChecker {
    fn new() -> Self {
        Self {
            check_count: Arc::new(Mutex::new(0)),
            check_latency_ms: Arc::new(Mutex::new(8.0)), // 8ms simulation
        }
    }

    async fn simulate_health_check(&self) {
        // Simulate health check processing
        let latency = {
            let lat = self.check_latency_ms.lock().await;
            *lat
        };
        
        tokio::time::sleep(Duration::from_millis(latency as u64)).await;
        
        // Increment check count
        {
            let mut count = self.check_count.lock().await;
            *count += 1;
        }
    }
}

// Benchmark functions

/// Benchmark cross-ExEx communication latency
fn bench_cross_exex_communication(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("cross_exex_communication");
    group.significance_level(0.1).sample_size(100);
    
    // Test different message sizes
    for message_size in [64, 256, 1024, 4096].iter() {
        let instance = &context.instances[0];
        
        group.throughput(Throughput::Bytes(*message_size as u64));
        group.bench_with_input(
            BenchmarkId::new("message_latency", message_size),
            message_size,
            |b, _size| {
                b.to_async(&*context.runtime).iter(|| async {
                    let latency = instance.send_message_benchmark().await;
                    black_box(latency)
                });
            },
        );
    }
    
    group.finish();
}

/// Benchmark RAG query performance
fn bench_rag_query_performance(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("rag_query_performance");
    group.significance_level(0.1).sample_size(200);
    
    // Test different query complexities
    let test_queries = [
        ("simple", "find transaction"),
        ("medium", "analyze defi protocol compound lending rates"),
        ("complex", "identify mev opportunities in uniswap v3 ethereum mainnet with arbitrage potential greater than 0.5%"),
        ("very_complex", "perform comprehensive analysis of cross-chain liquidity fragmentation impact on automated market maker efficiency across ethereum polygon arbitrum optimism including temporal patterns and risk assessments"),
    ];
    
    for (complexity, query) in test_queries.iter() {
        let instance = &context.instances[2]; // Use optimizer instance
        
        group.throughput(Throughput::Elements(1));
        group.bench_with_input(
            BenchmarkId::new("query_latency", complexity),
            query,
            |b, query| {
                b.to_async(&*context.runtime).iter(|| async {
                    let latency = instance.rag_query_benchmark(query).await;
                    black_box(latency)
                });
            },
        );
    }
    
    group.finish();
}

/// Benchmark memory operations
fn bench_memory_operations(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("memory_operations");
    group.significance_level(0.1).sample_size(500);
    
    // Test different memory operation sizes
    for size in [1024, 8192, 65536, 524288].iter() {
        let instance = &context.instances[1]; // Use analyzer instance
        
        group.throughput(Throughput::Bytes(*size as u64));
        group.bench_with_input(
            BenchmarkId::new("memory_latency", size),
            size,
            |b, size| {
                b.to_async(&*context.runtime).iter(|| async {
                    let latency = instance.memory_operation_benchmark(*size).await;
                    black_box(latency)
                });
            },
        );
    }
    
    group.finish();
}

/// Benchmark AI decision making
fn bench_ai_decision_making(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("ai_decision_making");
    group.significance_level(0.1).sample_size(150);
    
    // Test different transaction complexities
    let transaction_data = [
        ("simple_transfer", vec![0u8; 100]),
        ("defi_swap", vec![1u8; 500]),
        ("complex_contract", vec![2u8; 2000]),
        ("batch_transaction", vec![3u8; 10000]),
    ];
    
    for (tx_type, data) in transaction_data.iter() {
        let instance = &context.instances[1]; // Use analyzer instance
        
        group.throughput(Throughput::Bytes(data.len() as u64));
        group.bench_with_input(
            BenchmarkId::new("ai_decision_latency", tx_type),
            data,
            |b, data| {
                b.to_async(&*context.runtime).iter(|| async {
                    let latency = instance.ai_decision_benchmark(data).await;
                    black_box(latency)
                });
            },
        );
    }
    
    group.finish();
}

/// Benchmark batch processing throughput
fn bench_batch_processing(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("batch_processing");
    group.significance_level(0.1).sample_size(50);
    
    // Test different batch sizes
    for batch_size in [10, 100, 1000, 5000].iter() {
        let instance = &context.instances[2]; // Use optimizer instance
        
        group.throughput(Throughput::Elements(*batch_size as u64));
        group.bench_with_input(
            BenchmarkId::new("batch_throughput", batch_size),
            batch_size,
            |b, size| {
                b.to_async(&*context.runtime).iter(|| async {
                    let latency = instance.batch_processing_benchmark(*size).await;
                    black_box(latency)
                });
            },
        );
    }
    
    group.finish();
}

/// Benchmark health monitoring
fn bench_health_monitoring(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("health_monitoring");
    group.significance_level(0.1).sample_size(300);
    
    let instance = &context.instances[3]; // Use monitor instance
    
    group.throughput(Throughput::Elements(1));
    group.bench_function("health_check_latency", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let latency = instance.health_check_benchmark().await;
            black_box(latency)
        });
    });
    
    group.finish();
}

/// Benchmark concurrent operations (stress test)
fn bench_concurrent_operations(c: &mut Criterion) {
    let config = BenchmarkConfig {
        stress_concurrency: 50,
        ..Default::default()
    };
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("concurrent_operations");
    group.significance_level(0.1).sample_size(20);
    
    // Test concurrent message sending
    group.bench_function("concurrent_messages", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let instance = &context.instances[0];
            let mut handles = Vec::new();
            
            for _ in 0..config.stress_concurrency {
                let instance = instance.clone();
                let handle = tokio::spawn(async move {
                    instance.send_message_benchmark().await
                });
                handles.push(handle);
            }
            
            let results: Vec<_> = futures_util::future::join_all(handles).await;
            let total_latency: Duration = results
                .into_iter()
                .map(|r| r.unwrap_or(Duration::ZERO))
                .sum();
            
            black_box(total_latency)
        });
    });
    
    // Test concurrent RAG queries
    group.bench_function("concurrent_rag_queries", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let instance = &context.instances[2];
            let mut handles = Vec::new();
            
            for i in 0..config.stress_concurrency {
                let instance = instance.clone();
                let query = format!("test query {}", i);
                let handle = tokio::spawn(async move {
                    instance.rag_query_benchmark(&query).await
                });
                handles.push(handle);
            }
            
            let results: Vec<_> = futures_util::future::join_all(handles).await;
            let total_latency: Duration = results
                .into_iter()
                .map(|r| r.unwrap_or(Duration::ZERO))
                .sum();
            
            black_box(total_latency)
        });
    });
    
    // Test concurrent AI decisions
    group.bench_function("concurrent_ai_decisions", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let instance = &context.instances[1];
            let mut handles = Vec::new();
            
            for i in 0..config.stress_concurrency {
                let instance = instance.clone();
                let data = format!("transaction_data_{}", i).into_bytes();
                let handle = tokio::spawn(async move {
                    instance.ai_decision_benchmark(&data).await
                });
                handles.push(handle);
            }
            
            let results: Vec<_> = futures_util::future::join_all(handles).await;
            let total_latency: Duration = results
                .into_iter()
                .map(|r| r.unwrap_or(Duration::ZERO))
                .sum();
            
            black_box(total_latency)
        });
    });
    
    group.finish();
}

/// Benchmark multi-instance coordination
fn bench_multi_instance_coordination(c: &mut Criterion) {
    let config = BenchmarkConfig {
        instance_count: 4,
        ..Default::default()
    };
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("multi_instance_coordination");
    group.significance_level(0.1).sample_size(30);
    
    group.bench_function("coordination_consensus", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            // Simulate consensus decision across all instances
            let mut handles = Vec::new();
            
            for instance in &context.instances {
                let instance = instance.clone();
                let handle = tokio::spawn(async move {
                    // Simulate consensus participation
                    let ai_latency = instance.ai_decision_benchmark(b"consensus_data").await;
                    let msg_latency = instance.send_message_benchmark().await;
                    ai_latency + msg_latency
                });
                handles.push(handle);
            }
            
            let results: Vec<_> = futures_util::future::join_all(handles).await;
            let max_latency = results
                .into_iter()
                .map(|r| r.unwrap_or(Duration::ZERO))
                .max()
                .unwrap_or(Duration::ZERO);
            
            black_box(max_latency)
        });
    });
    
    group.bench_function("knowledge_sharing", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            // Simulate RAG context sharing between instances
            let mut handles = Vec::new();
            
            for (i, instance) in context.instances.iter().enumerate() {
                let instance = instance.clone();
                let query = format!("shared_knowledge_query_{}", i);
                let handle = tokio::spawn(async move {
                    instance.rag_query_benchmark(&query).await
                });
                handles.push(handle);
            }
            
            let results: Vec<_> = futures_util::future::join_all(handles).await;
            let total_latency: Duration = results
                .into_iter()
                .map(|r| r.unwrap_or(Duration::ZERO))
                .sum();
            
            black_box(total_latency)
        });
    });
    
    group.finish();
}

/// Benchmark resource usage and efficiency
fn bench_resource_efficiency(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("resource_efficiency");
    group.significance_level(0.1).sample_size(100);
    
    // Benchmark memory efficiency
    group.bench_function("memory_efficiency", |b| {
        b.iter_batched(
            || {
                // Setup: create fresh instance for each iteration
                Arc::new(MockBenchmarkInstance::new(
                    "memory_test".to_string(),
                    InstanceRole::Optimizer,
                ))
            },
            |instance| {
                context.runtime.block_on(async {
                    // Perform series of memory operations
                    let mut total_time = Duration::ZERO;
                    for size in [1024, 4096, 16384, 65536] {
                        let latency = instance.memory_operation_benchmark(size).await;
                        total_time += latency;
                    }
                    
                    // Get memory metrics
                    let metrics = instance.get_metrics().await;
                    black_box((total_time, metrics.memory_usage_bytes))
                })
            },
            BatchSize::SmallInput,
        );
    });
    
    // Benchmark cache efficiency
    group.bench_function("cache_efficiency", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let instance = &context.instances[2]; // Optimizer instance
            
            // Perform repeated queries (should hit cache)
            let mut total_time = Duration::ZERO;
            for _ in 0..10 {
                let latency = instance.rag_query_benchmark("repeated_query").await;
                total_time += latency;
            }
            
            black_box(total_time)
        });
    });
    
    group.finish();
}

/// Performance validation benchmark (validates SVM speed requirements)
fn bench_performance_validation(c: &mut Criterion) {
    let config = BenchmarkConfig::default();
    let context = BenchmarkContext::new(config);
    
    let mut group: BenchmarkGroup<WallTime> = c.benchmark_group("performance_validation");
    group.significance_level(0.1).sample_size(1000);
    
    // Validate RAG query latency (<50ms requirement)
    group.bench_function("rag_latency_validation", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let instance = &context.instances[2];
            let start = Instant::now();
            instance.rag_query_benchmark("validation query").await;
            let latency = start.elapsed();
            
            // Assert latency requirement in benchmark
            assert!(
                latency < Duration::from_millis(50),
                "RAG latency {} exceeds 50ms requirement",
                latency.as_millis()
            );
            
            black_box(latency)
        });
    });
    
    // Validate memory operation latency (<10ms requirement)
    group.bench_function("memory_latency_validation", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let instance = &context.instances[1];
            let start = Instant::now();
            instance.memory_operation_benchmark(4096).await;
            let latency = start.elapsed();
            
            // Assert latency requirement in benchmark
            assert!(
                latency < Duration::from_millis(10),
                "Memory operation latency {} exceeds 10ms requirement",
                latency.as_millis()
            );
            
            black_box(latency)
        });
    });
    
    // Validate communication latency (<5ms requirement)
    group.bench_function("communication_latency_validation", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let instance = &context.instances[0];
            let start = Instant::now();
            instance.send_message_benchmark().await;
            let latency = start.elapsed();
            
            // Assert latency requirement in benchmark
            assert!(
                latency < Duration::from_millis(5),
                "Communication latency {} exceeds 5ms requirement",
                latency.as_millis()
            );
            
            black_box(latency)
        });
    });
    
    group.finish();
}

/// Comprehensive stress test benchmark
fn bench_stress_test(c: &mut Criterion) {
    let config = BenchmarkConfig {
        stress_concurrency: 200,
        throughput_iterations: 5000,
        ..Default::default()
    };
    let context = BenchmarkContext::new(config);
    
    let mut group = c.benchmark_group("stress_test");
    group.significance_level(0.1).sample_size(10);
    group.measurement_time(Duration::from_secs(30)); // Longer measurement time for stress tests
    
    group.bench_function("full_system_stress", |b| {
        b.to_async(&*context.runtime).iter(|| async {
            let start = Instant::now();
            let mut handles = Vec::new();
            
            // Simulate high load across all instances
            for instance in &context.instances {
                for _ in 0..config.stress_concurrency / context.instances.len() {
                    // Mix of different operations
                    let instance = instance.clone();
                    let handle = tokio::spawn(async move {
                        let mut latencies = Vec::new();
                        
                        // AI decision
                        latencies.push(instance.ai_decision_benchmark(b"stress_test_data").await);
                        
                        // RAG query
                        latencies.push(instance.rag_query_benchmark("stress test query").await);
                        
                        // Memory operation
                        latencies.push(instance.memory_operation_benchmark(8192).await);
                        
                        // Message send
                        latencies.push(instance.send_message_benchmark().await);
                        
                        // Health check
                        latencies.push(instance.health_check_benchmark().await);
                        
                        latencies.into_iter().sum::<Duration>()
                    });
                    handles.push(handle);
                }
            }
            
            // Wait for all operations to complete
            let results: Vec<_> = futures_util::future::join_all(handles).await;
            let total_operations = results.len();
            let successful_operations = results
                .into_iter()
                .filter(|r| r.is_ok())
                .count();
            
            let total_time = start.elapsed();
            let success_rate = successful_operations as f64 / total_operations as f64;
            let throughput = total_operations as f64 / total_time.as_secs_f64();
            
            // Validate stress test requirements
            assert!(
                success_rate >= 0.95,
                "Stress test success rate {} below 95% requirement",
                success_rate
            );
            
            assert!(
                throughput >= 100.0,
                "Stress test throughput {} below 100 ops/sec requirement",
                throughput
            );
            
            black_box((total_time, success_rate, throughput))
        });
    });
    
    group.finish();
}

// Criterion benchmark groups
criterion_group!(
    name = integration_benches;
    config = Criterion::default()
        .measurement_time(Duration::from_secs(10))
        .warm_up_time(Duration::from_secs(3))
        .with_plots();
    targets = 
        bench_cross_exex_communication,
        bench_rag_query_performance,
        bench_memory_operations,
        bench_ai_decision_making,
        bench_batch_processing,
        bench_health_monitoring,
        bench_performance_validation
);

criterion_group!(
    name = stress_benches;
    config = Criterion::default()
        .measurement_time(Duration::from_secs(20))
        .warm_up_time(Duration::from_secs(5))
        .sample_size(10);
    targets = 
        bench_concurrent_operations,
        bench_multi_instance_coordination,
        bench_resource_efficiency,
        bench_stress_test
);

criterion_main!(integration_benches, stress_benches);